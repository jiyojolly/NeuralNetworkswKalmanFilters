{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd34ea97405b3902d4925a75b46b982e",
     "grade": false,
     "grade_id": "cell-0a8316b039d048ad",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise 1. A multilayer perceptron network\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "The goal of this exercise is to get familiar with the basics of PyTorch and train a simple feedforward network on a real-world data set. If you are not familiar with PyTorch, there is a number of good tutorials [here](https://pytorch.org/tutorials/index.html). We recommend the following ones:\n",
    "* [What is PyTorch?](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)\n",
    "* [Autograd: Automatic Differentiation](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py)\n",
    "* [Learning PyTorch with Examples](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html)\n",
    "* [Neural Networks](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py)\n",
    "\n",
    "This exercise consists of several tasks which require some background knowledge of basic ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False  #Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65e2970339980ef7d85c3754662c4ee8",
     "grade": true,
     "grade_id": "evaluation_settings",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "351dfcae9c688c72cab8ba805d82882c",
     "grade": false,
     "grade_id": "cell-01498dc3f73989b5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\NLP_Project\\NeuralNetworkswKalmanFilters\\Examples\\PytorchExample\\1_mlp\n",
      "The data directory is ..\\..\\..\\data\n"
     ]
    }
   ],
   "source": [
    "# Select data directory\n",
    "import os\n",
    "print(os.getcwd())\n",
    "if os.path.isdir('/coursedata'):\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('..\\..\\..\\data/'):\n",
    "    course_data_dir = '..\\..\\..\\data'\n",
    "else:\n",
    "    # Specify course_data_dir on your machine\n",
    "    # course_data_dir = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9948c1cbf3480ee5b2a9c2a397921ec",
     "grade": false,
     "grade_id": "cell-7643a1c4336569b4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Select device which you are going to use for training\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc5c0195206dae40876fe429916217c4",
     "grade": false,
     "grade_id": "cell-70232a39ccf9c751",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c86a077d5d534679bd3f597ac6a6bdce",
     "grade": false,
     "grade_id": "cell-ce13efdf413792bd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "We are going to use *winequality* dataset which contains red and white vinho verde wine samples rated by experts from 0 to 10 (obtained from [here](https://archive.ics.uci.edu/ml/datasets/wine+quality)). We will transform the task into a binary classification problem and try to predict if the quality of wine is greater or lower than 7. The idea is to compare the quality of predictions obtained by a random forest classfier and a simple neural network.\n",
    "\n",
    "Let us load the data and split it into the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e33090c95b149fec5aec93c5e199a4f",
     "grade": false,
     "grade_id": "cell-bc3a08be26d3616e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from ..\\..\\..\\data\\winequality\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(course_data_dir, 'winequality')\n",
    "print('Data loaded from %s' % data_dir)\n",
    "\n",
    "df = pd.concat([\n",
    "    pd.read_csv(os.path.join(data_dir, 'winequality-red.csv'), delimiter=';'),\n",
    "    pd.read_csv(os.path.join(data_dir, 'winequality-white.csv'), delimiter=';')\n",
    "])\n",
    "\n",
    "x = df.loc[:, df.columns != 'quality'].values\n",
    "y = df['quality'].values >= 7  # Convert to a binary classification problem\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle=True)\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "356da8829de19d89765b10c3ff4aabb3",
     "grade": false,
     "grade_id": "cell-fff001b57c687c28",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Train a Random forest classifier\n",
    "\n",
    "*In the code below, train a random forest classifier from sklearn (look at the description [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)) using `x_train` and `y_train` with 100 trees. Name your classifier object `classifier`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97dc62b85ec7d20b7554e453e3e33fd5",
     "grade": false,
     "grade_id": "cell-92782487f52a6c3e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "# classifier = ...\n",
    "# YOUR CODE HERE\n",
    "classifier = RandomForestClassifier(n_estimators = 100)\n",
    "classifier = classifier.fit(x_train, y_train)\n",
    "print(classifier)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc8909cddf05a5f36de2499f483edede",
     "grade": true,
     "grade_id": "rf_accuracy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest: 0.89\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94      1064\n",
      "           1       0.78      0.58      0.67       236\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      1300\n",
      "   macro avg       0.85      0.77      0.80      1300\n",
      "weighted avg       0.89      0.89      0.89      1300\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x27ab89a9080>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27ab1960358>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the accuracy of the random forest classifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "pred_test = classifier.predict(x_test)  # Predict labels of test data using the trained classifier\n",
    "c_matrix = confusion_matrix(y_test, pred_test) \n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, pred_test)\n",
    "print(\"Accuracy of random forest: {:.2f}\".format(rf_accuracy))\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, pred_test))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(4, 4))\n",
    "ax.set_title(\"Confusion matrix\")\n",
    "sns.heatmap(c_matrix, cmap='Blues', annot=True, fmt='g', cbar=False)\n",
    "ax.set_xlabel('predictions')\n",
    "ax.set_ylabel('true labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ecc61bbd856ff9141c9d0de211523be2",
     "grade": false,
     "grade_id": "cell-4d94c36293bfa64e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "As you can see, the random forest classifier works quite nicely in this task without much tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd8228d2186021aafe8fd809c2f229fa",
     "grade": false,
     "grade_id": "cell-76070c68689a5242",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## A multilayer perceptron (MLP) network with two hidden layers\n",
    "\n",
    "In the code below, define a neural network architecture with:\n",
    "- input dimensionality 11\n",
    "- one hidden layer with 100 units with ReLU nonlinearity\n",
    "- one hidden layer with 100 units with ReLU nonlinearity\n",
    "- linear output layer with output dimensionality 2.\n",
    "\n",
    "**Please do not use [`torch.nn.Sequential`](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential) in your code.**\n",
    "\n",
    "You may want to look at [this tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py) for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4838e01b283d2060c905d954da14d45d",
     "grade": false,
     "grade_id": "cell-c648be60aebb3433",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "n_inputs = 11\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "        self.fc1 = nn.Linear(11, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=11, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = MLP()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ec8a74e5889cec8c4cbc26bf8f79a54",
     "grade": true,
     "grade_id": "mlp_architecture",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let us create the network and make sure it can process a random input of the right shape\n",
    "mlp = MLP()\n",
    "y = mlp(torch.randn(10, n_inputs))\n",
    "assert y.shape == torch.Size([10, 2]), \"Bad shape of y: y.shape={}\".format(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c0975e13adc5dc011d2a5c49ce44813",
     "grade": false,
     "grade_id": "cell-4a3bd5bb745e59c6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "One can also create an instance of a simple deep network using [`torch.nn.Sequential`](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential).\n",
    "\n",
    "In the cell below, please use [`torch.nn.Sequential`](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential)\n",
    "to create an MLP with the same structure as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "009519638addd8d21556ddc8039f8523",
     "grade": false,
     "grade_id": "cell-1310c88e86ee652b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# This function should return an MLP model created with torch.nn.Sequential\n",
    "# - input dimensionality 11\n",
    "# - one hidden layer with 100 units with ReLU nonlinearity\n",
    "# - one hidden layer with 100 units with ReLU nonlinearity\n",
    "# - linear output layer with output dimensionality 2.\n",
    "# mlp_seq = nn.Sequential(...\n",
    "# YOUR CODE HERE\n",
    "mlp_seq = nn.Sequential(\n",
    "    nn.Linear(11,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,2)\n",
    ")\n",
    "                        \n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ef31af1e5f75043643a15dde8696fe7",
     "grade": false,
     "grade_id": "cell-9aff5dc7e6aa2c3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=11, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the network\n",
    "print(mlp_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a6a6b214f3be7581a24ed938d6a2883",
     "grade": true,
     "grade_id": "mlp_Sequential",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let us feed a random input of the right shape to the network created with torch.nn.Sequential.\n",
    "y = mlp_seq(torch.randn(10, n_inputs))\n",
    "assert y.shape == torch.Size([10, 2]), \"Bad shape of y: y.shape={}\".format(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0150363a62c9680543f7697e313a5675",
     "grade": false,
     "grade_id": "cell-70cbd420870116d7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Train an MLP network\n",
    "\n",
    "Next we will train the multilayer perceptron network. For better understanding of the training process you can take a look at [this part of the tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#backprop)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5fa7a839ecd25901b63e914bd53ec6c",
     "grade": false,
     "grade_id": "cell-0c16db048e765d97",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Data scaling\n",
    "\n",
    "Even though deep learning is supposed to work well on raw data without much feature engineering, it is usually a good idea to pre-process data so that the inputs have zero mean and unit standard deviation. PyTorch has its own tools for preprocessing but let us use sklearn's `StandardScaler` for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ca402794b8fd94bda252ab568e6a620",
     "grade": false,
     "grade_id": "cell-db601500e1d7cd93",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2af318ff16206e2fe8425c37fac0204c",
     "grade": false,
     "grade_id": "cell-5a5f4579c7df733f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Let us implement the training loop. We will use the Adam optimizer with learning rate 0.01 and we will process the data in the full-batch model (without splitting the data into mini-batches).\n",
    "\n",
    "*Your task is to insert the missing code. You may find it useful to look at [this tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py).*\n",
    "Your should have the following steps:\n",
    "* Transform `x_train_scaled` and `y_train` to `torch.tensor`, make sure the tensors have proper types and they go to the specified `device`.\n",
    "* Set all gradient values to zeros.\n",
    "* Calculate outputs of the MLP network (call them `outputs`).\n",
    "* Calculate cross entropy loss using [`torch.nn.functional.cross_entropy`](https://pytorch.org/docs/stable/nn.html#torch.nn.functional.cross_entropy).\n",
    "* Backpropagate the loss: compute the gradients of the loss wrt to all the parameters of the MLP.\n",
    "* Update the parameters of the model using the `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MLP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0c0e681ae1b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MLP' is not defined"
     ]
    }
   ],
   "source": [
    "mlp = MLP()\n",
    "mpl = mlp.to(device)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.005)\n",
    "n_epochs = 1000\n",
    "\n",
    "train_accuracy_history = []\n",
    "test_accuracy_history = []\n",
    "\n",
    "x_train = torch.tensor(x_train_scaled, device=device, dtype=torch.float)\n",
    "y_train = torch.tensor(y_train, device=device, dtype=torch.long)\n",
    "\n",
    "ceLoss = nn.CrossEntropyLoss()\n",
    "mlp.zero_grad()\n",
    "#Calculate outputs with forward()\n",
    "outputs = mlp(x_train)\n",
    "outputs.backward(gradient=torch.ones(outputs.size(),device=device))\n",
    "\n",
    "for f in mlp.parameters():\n",
    "    print('data is')\n",
    "    print(f.data.shape)\n",
    "    print('grad is')\n",
    "    print(f.grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0c2fc142dd0cdfa9399db8ec15f7f3d",
     "grade": false,
     "grade_id": "cell-692ef1b990bd1bbc",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 11])\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiyoj\\AppData\\Local\\conda\\conda\\envs\\dle\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-8f30010a3796>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# mlp = MLP()\n",
    "# mpl = mlp.to(device)\n",
    "# optimizer = torch.optim.Adam(mlp.parameters(), lr=0.005)\n",
    "# n_epochs = 1000\n",
    "\n",
    "# train_accuracy_history = []\n",
    "# test_accuracy_history = []\n",
    "\n",
    "# x_train = torch.tensor(x_train_scaled, device=device, dtype=torch.float, requires_grad = True)\n",
    "# y_train = torch.tensor(y_train, device=device, dtype=torch.long)\n",
    "\n",
    "# ceLoss = nn.CrossEntropyLoss()\n",
    "\n",
    "# for epoch in range(n_epochs):\n",
    "#     # - You need to specify dtype when converting data to torch.tensor\n",
    "#     # - Call the outputs of the model \"outputs\" like in the line below\n",
    "#     # outputs =  mlp.forward(...)\n",
    "#     # YOUR CODE HERE\n",
    "#     #raise NotImplementedError()\n",
    "#     #Set gradients as zero\n",
    "#     mlp.zero_grad()\n",
    "#     #Calculate outputs with forward()\n",
    "#     outputs = mlp(x_train)   \n",
    "#     outputs.backward(gradient=torch.ones(outputs.size(),device=device))\n",
    "#     print(mlp_seq[0].weight.shape)\n",
    "#     print(mlp_seq[0].weight.requires_grad)\n",
    "#     print(mlp_seq[0].weight.grad.shape)\n",
    "  \n",
    "\n",
    "\n",
    "# #     #calculate loss\n",
    "# #     loss = ceLoss(outputs, y_train)\n",
    "# #     #claculate gradients \n",
    "# #     loss.backward()\n",
    "    \n",
    "#     #update weights using optimizer\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     if skip_training:\n",
    "#         break\n",
    "\n",
    "# #     if (epoch % 1) == 0:\n",
    "# #         # Store the progress of training\n",
    "# #         with torch.no_grad():\n",
    "# #             # outputs is the output of the model produced with forward function\n",
    "# #             logits = outputs.cpu().data.numpy()\n",
    "# #             pred_train = logits.argmax(axis=1)\n",
    "# #             print(max(pred_train))\n",
    "# #             train_accuracy = accuracy_score(pred_train, y_train.cpu())\n",
    "\n",
    "# #             # Compute test error\n",
    "# #             x = torch.tensor(x_test_scaled, device=device, dtype=torch.float)\n",
    "# #             outputs = mlp.forward(x)\n",
    "# #             logits = outputs.cpu().data.numpy()\n",
    "# #             pred_test = logits.argmax(axis=1)\n",
    "# #             print(max(pred_train))\n",
    "# #             test_accuracy = accuracy_score(pred_test, y_test)\n",
    "# #             train_accuracy_history.append(train_accuracy)\n",
    "# #             test_accuracy_history.append(test_accuracy)\n",
    "# #             print('Train Epoch {}: Loss: {:.6f} Train accuracy {:.2f} Test accuracy {:.2f}'.format(\n",
    "# #                 epoch, loss.item(), train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy should be comparable to the accuracy of the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43a179bfe2aaecbafa492f455d9e4694",
     "grade": true,
     "grade_id": "mlp_accuracy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Save the network to a file, submit this file together with your notebook\n",
    "filename = '1_mlp.pth'\n",
    "if not skip_training:\n",
    "    try:\n",
    "        do_save = input('Do you want to save the model (type yes to confirm)? ').lower()\n",
    "        if do_save == 'yes':\n",
    "            torch.save(mlp.state_dict(), filename)\n",
    "            print('Model saved to %s' % filename)\n",
    "        else:\n",
    "            print('Model not saved')\n",
    "    except:\n",
    "        raise Exception('The notebook should be run or validated with skip_training=False.')\n",
    "else:\n",
    "    mlp = MLP()\n",
    "    mlp.load_state_dict(torch.load(filename, map_location=lambda storage, loc: storage))\n",
    "    print('Model loaded from %s' % filename)\n",
    "    mlp = mlp.to(device)\n",
    "    mlp.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1408a9336753e05a66921a09ada8acca",
     "grade": false,
     "grade_id": "cell-ffa1381201dcd251",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let us plot the accuracies during training\n",
    "fig, ax = plt.subplots(1, figsize=(10, 5))\n",
    "ax.plot(train_accuracy_history, label='train')\n",
    "ax.plot(test_accuracy_history, label='test')\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6863798cde48e5895341793793d12196",
     "grade": false,
     "grade_id": "cell-339dff5131009354",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's print the classification report and plot the confusion matrix similarly to the random forest classifier.\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, pred_test))\n",
    "\n",
    "c_matrix = confusion_matrix(y_test, pred_test)\n",
    "fig, ax = plt.subplots(1, figsize=(4, 4))\n",
    "ax.set_title(\"Confusion matrix\")\n",
    "sns.heatmap(c_matrix, cmap='Blues', annot=True, fmt='g', cbar=False)\n",
    "ax.set_xlabel('predictions')\n",
    "ax.set_ylabel('true labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "750c239eaa2372aeea5e6154ee2b6f4b",
     "grade": false,
     "grade_id": "cell-ebc09a57c4ef9976",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Note that even though the random forest classifier may have better performance, the performance of the MLP network may be improved by tuning the hyperparameters, such as:\n",
    "* number of hidden units\n",
    "* number of layers\n",
    "* learning rate schedule\n",
    "* regularization methods.\n",
    "\n",
    "The message from this exercise is that in simple problems that do not have spatial (like in images) or temporal (like in time series) structure, alternative classifiers (like random forests) may do very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5478f97bfe97677a086b82e96d9ede7d",
     "grade": false,
     "grade_id": "cell-94367a22998608a6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Define an MLP with an arbitrary number of layers\n",
    "\n",
    "Let us now define a multilayer perceptron with an arbitrary number of layers and arbitrary number of neurons in each layer, so that an MLP can be created as follows:\n",
    "```python\n",
    "> mlp = FancyMLP([11, 150, 100, 50, 2], activation_fn=F.tanh)\n",
    "```\n",
    "In the example above, we created a network with three hidden layers: 150 units in the first hidden layer, 100 units in the second one and 50 units in the third one.\n",
    "\n",
    "Note: The same activation function should be applied to all the layers except for the last one. This way the MLP can be used either for regression or classification.\n",
    "\n",
    "Hints:\n",
    "* You may find it useful to use function [`torch.nn.Module.add_module`](https://pytorch.org/docs/master/nn.html#torch.nn.Module.add_module) or class [`torch.nn.ModuleList`](https://pytorch.org/docs/stable/nn.html#torch.nn.ModuleList).\n",
    "* Check how many trainable parameters a created MLP has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e68c9905776a8285d6d7a49edf390de",
     "grade": false,
     "grade_id": "cell-02639f9ae9ca2c7c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class FancyMLP(nn.Module):\n",
    "    def __init__(self, sizes, activation_fn=torch.tanh):\n",
    "        \"\"\"Multilayer perceptron with an arbitrary number of layers.\n",
    "        \n",
    "        Args:\n",
    "          sizes (list):             Number of units in each layer including the input and the output layer:\n",
    "                                    [n_inputs, n_units_in_hidden_layer1, ..., n_units_in_hidden_layerN, n_outputs]\n",
    "          activation_fn (callable): An element-wise function used in every layer except in the last one.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "        super(FancyMLP, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(sizes[0], sizes[1])])\n",
    "        self.linears.extend(nn.ModuleList([nn.Linear(sizes[i+1], sizes[i+2]) for i in range(len(sizes)-2)]))\n",
    "        self.activation = activation_fn\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "        for i in range(len(self.linears)-1):\n",
    "            x = self.activation(self.linears[i](x))\n",
    "        \n",
    "        x = self.linears[-1](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# fmlp = FancyMLP([11, 150, 100, 50, 2], F.tanh)\n",
    "# print(fmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36bcec862f655931e3615b08ba016771",
     "grade": true,
     "grade_id": "fancy_mlp",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let us now test your class\n",
    "mlp = FancyMLP([n_inputs, 100, 50, 2])\n",
    "y = mlp(torch.randn(10, n_inputs))\n",
    "assert y.shape == torch.Size([10, 2]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "mlp = FancyMLP([3, 10, 30, 40, 50, 5])\n",
    "y = mlp(torch.randn(10, 3))\n",
    "assert y.shape == torch.Size([10, 5]), \"Bad shape of y: y.shape={}\".format(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2fdc53bcc62d2b9103d8a83d599664d",
     "grade": true,
     "grade_id": "fancy_mlp_nparams",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Print the MLP\n",
    "mlp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
