{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning using EKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing Pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: D:\\From Web\\STUDIES\\EKF\n",
      "The data directory is \\EKF\n"
     ]
    }
   ],
   "source": [
    "# Select data directory\n",
    "print(\"Current Directory:\",os.getcwd())\n",
    "if os.path.isdir('/coursedata'):\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('..\\data/'):\n",
    "    course_data_dir = '..\\data'\n",
    "else:\n",
    "    # Specify course_data_dir on your machine\n",
    "    # course_data_dir = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Select device which you are going to use for training\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data Sets\n",
    "Testing using a toy sine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stored in \\EKF\\fashion_mnist\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Min-max scaling to [-1, 1]\n",
    "])\n",
    "\n",
    "data_dir = os.path.join(course_data_dir, 'fashion_mnist')\n",
    "print('Data stored in %s' % data_dir)\n",
    "trainset = torchvision.datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "           'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, n_rows=1):\n",
    "    fig, axs = plt.subplots(n_rows, images.size(0) // n_rows)\n",
    "    for ax, img in zip(axs.flat, images):\n",
    "        ax.matshow(img[0].cpu().numpy(), cmap=plt.cm.Greys)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    plt.tight_layout(w_pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "plot_images(images[:8], n_rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# x_train_scaled = scaler.fit_transform(x_train)\n",
    "# x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden_layer,n_outputs,bias=True):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(n_inputs,n_hidden_layer, bias)\n",
    "        self.fc2 = nn.Linear(n_hidden_layer, n_outputs ,bias)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = (self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing net\n",
    "n_inputs = 784\n",
    "n_outputs = 16\n",
    "n_hidden_layer = 32\n",
    "test_net = MLP(n_inputs, n_hidden_layer,n_outputs)\n",
    "test_net.to(device)\n",
    "# print(test_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(test_net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the accuracy on the test dataset\n",
    "def compute_accuracy(net, testloader):\n",
    "    test_net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            #print(images.size())\n",
    "            outputs = test_net(images.view(-1,784))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=10\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    print_every = 200  # mini-batches\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        # Transfer to GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #inputs= torch.tensor(inputs,device=device,dtype=torch.double)\n",
    "        #print(inputs.size())\n",
    "        inputs=inputs.view(-1,784)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = test_net(inputs)\n",
    "#         print(outputs.size())\n",
    "#         print(labels.size())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i % print_every) == (print_every-1):\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/print_every))\n",
    "            running_loss = 0.0\n",
    "#         if skip_training:\n",
    "#             break\n",
    "\n",
    "#     # Print accuracy after every epoch\n",
    "    accuracy = compute_accuracy(test_net, testloader)\n",
    "    print('Accuracy of the network on the test images: %.3f' % accuracy)\n",
    "\n",
    "# #     if skip_training:\n",
    "# #         break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using EKF for learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Calculate Weight size\n",
    "# weight_mat_size = 0\n",
    "# for i in range(len(layer_list)-1):\n",
    "#     weight_mat_size = weight_mat_size + (layer_list[i]*layer_list[i+1])\n",
    "        \n",
    "def getWeights(net):\n",
    "    weight_mat = []\n",
    "    for name,param in net.named_parameters():\n",
    "    \n",
    "        #print('Layer',name, 'is', param.data.shape)\n",
    "        if (len(list(param.data.shape)) == 2):\n",
    "            weight_mat.append(param.data.flatten())\n",
    "        \n",
    "    weight_mat = torch.cat(weight_mat, dim=0)       \n",
    "    #print('Shape of weight matrix', weight_mat.shape)\n",
    "    return weight_mat.view(-1, 1)\n",
    "\n",
    "def getWeightsgrad(net):\n",
    "    weight_grad_mat = []\n",
    "    for name,param in net.named_parameters():\n",
    "    \n",
    "        #print('Layer Grads',name, 'is', param.grad.shape)\n",
    "        if (len(list(param.grad.shape)) == 2):\n",
    "            weight_grad_mat.append(param.grad.flatten())\n",
    "        \n",
    "    weight_grad_mat = torch.cat(weight_grad_mat, dim=0)       \n",
    "    #print('Shape of weight matrix', weight_grad_mat.shape)   \n",
    "    return weight_grad_mat.view(-1, 1)\n",
    "\n",
    "def setWeights(net, weight_mat):\n",
    "    mem_ind = 0;\n",
    "    for name,param in net.named_parameters():\n",
    "        if (len(list(param.data.shape)) == 2):\n",
    "            #print('Layer',name, 'is', param.data.shape)\n",
    "            #print(torch.numel(param.data))\n",
    "            #print(weight_mat[mem_ind:mem_ind+torch.numel(param.data)].view(param.data.shape).shape)\n",
    "            param.data = weight_mat[mem_ind:mem_ind+torch.numel(param.data)].view(param.data.shape)\n",
    "            mem_ind = torch.numel(param.data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing network MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=10, bias=False)\n",
      "  (fc2): Linear(in_features=10, out_features=10, bias=False)\n",
      ")\n",
      "torch.Size([7940, 7940])\n"
     ]
    }
   ],
   "source": [
    "# Define number of Input and Output layers\n",
    "device='cpu'\n",
    "torch.set_default_dtype(torch.float32)\n",
    "n_inputs = 784\n",
    "n_outputs=10\n",
    "batch_size=10\n",
    "n_hidden_layer = 10\n",
    "mlp_EKF = MLP(n_inputs,n_hidden_layer,n_outputs,bias = False)\n",
    "mlp_EKF = mlp_EKF.to(device)\n",
    "n_epochs = 1\n",
    "\n",
    "print(\"Printing network\",mlp_EKF)\n",
    "\n",
    "# Define EKF covariances\n",
    "#weight_mat = getWeights(mlp_EKF).to(device)\n",
    "# System Noise or also known as training  noise  \n",
    "\n",
    "Q = 1e-6*torch.eye((getWeights(mlp_EKF).shape[0]),device=device, dtype=torch.float32)\n",
    "# Measurement noise or noise in targets / Learning rate\n",
    "R = 10*torch.eye(batch_size*n_outputs,device=device, dtype=torch.float32)\n",
    "#Covariance Matrix\n",
    "P = 100*torch.eye((getWeights(mlp_EKF).shape[0]),device=device, dtype=torch.float32)\n",
    "print(P.size())\n",
    "\n",
    "#print(weight_mat.shape)\n",
    "#print(x_train.shape)\n",
    "#print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_loss(outputs,labels):\n",
    "    \n",
    "    return (labels-outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_err_loss(outputs,labels):\n",
    "#     loss= torch.sqrt(-(labels*torch.log(outputs)+(torch.ones(labels.shape[0])-labels)*torch.log(torch.ones(labels.shape[0])-outputs)))\n",
    "#     return loss     \n",
    "cross_err_loss=nn.BCEWithLogitsLoss(reduction='none')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net loss tensor(0.6950, grad_fn=<MeanBackward1>)\n",
      "Shape of Kalman gain torch.Size([7940, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net loss tensor(0.7222, grad_fn=<MeanBackward1>)\n",
      "Shape of Kalman gain torch.Size([7940, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net loss tensor(0.6562, grad_fn=<MeanBackward1>)\n",
      "Shape of Kalman gain torch.Size([7940, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net loss tensor(0.7987, grad_fn=<MeanBackward1>)\n",
      "Shape of Kalman gain torch.Size([7940, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net loss tensor(0.8291, grad_fn=<MeanBackward1>)\n",
      "Shape of Kalman gain torch.Size([7940, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net loss tensor(0.9729, grad_fn=<MeanBackward1>)\n",
      "Shape of Kalman gain torch.Size([7940, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net loss tensor(1.2394, grad_fn=<MeanBackward1>)\n",
      "Shape of Kalman gain torch.Size([7940, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net loss tensor(2.6476, grad_fn=<MeanBackward1>)\n",
      "Shape of Kalman gain torch.Size([7940, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net loss tensor(21.1095, grad_fn=<MeanBackward1>)\n",
      "Shape of Kalman gain torch.Size([7940, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Krishnananda Prabhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net loss tensor(10519.1387, grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Lapack Error getrf : U(26,26) is 0, U is singular at c:\\a\\w\\1\\s\\tmp_conda_3.6_104352\\conda\\conda-bld\\pytorch_1550400396997\\work\\aten\\src\\th\\generic/THTensorLapack.cpp:555",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-9f2551b3c752>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m#print(\"Shape of Weight Grad Mat\", H)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m#update weights using EKF filter Update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mAk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[1;31m#print(Ak)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m#Ak = torch.ones(1).view(1,1).to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Lapack Error getrf : U(26,26) is 0, U is singular at c:\\a\\w\\1\\s\\tmp_conda_3.6_104352\\conda\\conda-bld\\pytorch_1550400396997\\work\\aten\\src\\th\\generic/THTensorLapack.cpp:555"
     ]
    }
   ],
   "source": [
    "#x_train = torch.tensor(x_train, device=device, dtype=torch.float64)\n",
    "#y_train = torch.tensor(y_train, device=device, dtype=torch.float64)\n",
    "\n",
    "#ceLoss = nn.MSELoss(reduction='none')\n",
    "\n",
    "# Plotting before learning \n",
    "#fig, ax = plt.subplots(1)\n",
    "#ax.plot(x_train.cpu().numpy(), y_train.cpu().numpy(), '.')\n",
    "\n",
    "n_epochs=10\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    #outputs = [] \n",
    "    #Calling Backward for each sample\n",
    "   \n",
    "    for i,(inputs,labels) in enumerate(trainloader,0):\n",
    "        loss=[]\n",
    "        H=[]\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #print(labels)\n",
    "        inputs= torch.tensor(inputs,device=device,dtype=torch.float32).view(-1,784)\n",
    "        labels= torch.tensor(labels,device=device,dtype=torch.long)\n",
    "        outputs = mlp_EKF(inputs)\n",
    "\n",
    "        #outputs.append(output)\n",
    "        #print(\"Update for Batch\",i)\n",
    "        mlp_EKF.zero_grad()\n",
    "        #print(label_vector)\n",
    "        #loss = criterion(outputs, labels)\n",
    "\n",
    "        for i in range(outputs.shape[0]):\n",
    "            label_vector=torch.zeros(outputs.shape[1]).to(device)\n",
    "            label_vector[labels]=1\n",
    "                \n",
    "            #print(outputs[i].shape)\n",
    "            #print(label_vector.shape)\n",
    "            err=cross_err_loss(outputs[i],label_vector)\n",
    "            #print(loss.size())\n",
    "            loss.append(err) \n",
    "            for j in range(err.shape[0]):\n",
    "                err[j].backward(retain_graph=True)\n",
    "        \n",
    "                H.append(getWeightsgrad(mlp_EKF).to(device).view(-1))\n",
    "                \n",
    "                \n",
    "        loss=torch.cat(loss).view(-1,1)\n",
    "        net_loss=torch.mean(loss)\n",
    "        print('Net loss',net_loss)\n",
    "        H=torch.stack(H,dim=0)\n",
    "#         print(loss.shape)\n",
    "#         print(H.size())\n",
    "#         print(P.size())\n",
    "        #print(\"Shape of Weight Grad Mat\", H)\n",
    "        #update weights using EKF filter Update\n",
    "        Ak = torch.inverse(R + torch.mm(torch.mm(H, P), torch.transpose(H,0,1)))\n",
    "        #print(Ak)\n",
    "        #Ak = torch.ones(1).view(1,1).to(device)\n",
    "        Kk = torch.mm(torch.mm(P, torch.transpose(H,0,1)), Ak)\n",
    "        \n",
    "        #Kk = torch.ones((120,1)).to(device)\n",
    "        #print(weight_mat.shape)\n",
    "        print(\"Shape of Kalman gain\",Kk.shape)\n",
    "        #print(\"Shape of loss\",loss.shape)\n",
    "        #print(\"Shape of mul term\",torch.mm(Kk, loss).shape)\n",
    "        #print(\"Weight Mat Shape\",weight_mat)\n",
    "        #print(loss)\n",
    "        weight_mat= getWeights(mlp_EKF).to(device)\n",
    "        weight_mat = weight_mat + torch.mm(Kk, loss)\n",
    "        #print(\"Weight Mat Shape\",weight_mat.shape)\n",
    "        P = P + Q - torch.mm(torch.mm(Kk,H),P)\n",
    "        setWeights(mlp_EKF,weight_mat)\n",
    "        \n",
    "    #print(\"Weight\",weight_mat)\n",
    "    #outputs = torch.cat(outputs, dim=0)\n",
    "    \n",
    "    #Plotting Output\n",
    "#     ax.clear()\n",
    "#     plt_x_train = inputs.cpu().detach().numpy()\n",
    "#     plt_y_train = y_train.cpu().detach().numpy()\n",
    "#     plt_outputs = outputs.cpu().detach().numpy()\n",
    "#     ax.plot(plt_x_train, plt_y_train, '.')\n",
    "#     ax.plot(plt_x_train, plt_outputs, 'r-')\n",
    "#     ax.grid(True)\n",
    "#     ax.set_title('Iteration %d/%d' % (epoch+1, n_epochs))\n",
    "    display.clear_output(wait=True)\n",
    "#     display.display(fig)\n",
    "#     plt.pause(0.005)\n",
    "    \n",
    "# display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
